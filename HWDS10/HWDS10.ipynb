{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n",
      "Training Simple RNN model...\n",
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 182ms/step - accuracy: 0.5737 - loss: 0.6632 - val_accuracy: 0.6544 - val_loss: 0.6219\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 191ms/step - accuracy: 0.7449 - loss: 0.5177 - val_accuracy: 0.6970 - val_loss: 0.5742\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 183ms/step - accuracy: 0.8181 - loss: 0.4145 - val_accuracy: 0.8148 - val_loss: 0.4624\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 193ms/step - accuracy: 0.7702 - loss: 0.4640 - val_accuracy: 0.6546 - val_loss: 0.6212\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 202ms/step - accuracy: 0.8038 - loss: 0.4335 - val_accuracy: 0.7660 - val_loss: 0.5357\n",
      "782/782 - 30s - 38ms/step - accuracy: 0.7682 - loss: 0.5247\n",
      "Accuracy on test set: 0.7682399749755859\n",
      "Training LSTM model...\n",
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 815ms/step - accuracy: 0.6876 - loss: 0.5796 - val_accuracy: 0.8390 - val_loss: 0.3786\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 835ms/step - accuracy: 0.8851 - loss: 0.2945 - val_accuracy: 0.8676 - val_loss: 0.3195\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 899ms/step - accuracy: 0.8909 - loss: 0.2610 - val_accuracy: 0.6884 - val_loss: 0.6643\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 858ms/step - accuracy: 0.8107 - loss: 0.4043 - val_accuracy: 0.8046 - val_loss: 0.5010\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 842ms/step - accuracy: 0.9218 - loss: 0.2000 - val_accuracy: 0.8436 - val_loss: 0.3817\n",
      "782/782 - 113s - 145ms/step - accuracy: 0.8453 - loss: 0.3813\n",
      "Accuracy on test set: 0.8452799916267395\n",
      "Training Bidirectional LSTM model...\n",
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 2s/step - accuracy: 0.6407 - loss: 0.6105 - val_accuracy: 0.7868 - val_loss: 0.4365\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 2s/step - accuracy: 0.8726 - loss: 0.3079 - val_accuracy: 0.8230 - val_loss: 0.4857\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m725s\u001b[0m 2s/step - accuracy: 0.9198 - loss: 0.2182 - val_accuracy: 0.8636 - val_loss: 0.3304\n",
      "Epoch 4/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 2s/step - accuracy: 0.8844 - loss: 0.2830 - val_accuracy: 0.8218 - val_loss: 0.4078\n",
      "Epoch 5/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 2s/step - accuracy: 0.7848 - loss: 0.4561 - val_accuracy: 0.8170 - val_loss: 0.4833\n",
      "782/782 - 123s - 157ms/step - accuracy: 0.8132 - loss: 0.5041\n",
      "Accuracy on test set: 0.8131999969482422\n",
      "Training Deep LSTM model...\n",
      "Epoch 1/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 2s/step - accuracy: 0.6667 - loss: 0.5920 - val_accuracy: 0.7134 - val_loss: 0.6119\n",
      "Epoch 2/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m859s\u001b[0m 3s/step - accuracy: 0.8153 - loss: 0.4219 - val_accuracy: 0.8674 - val_loss: 0.3205\n",
      "Epoch 3/5\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 3s/step - accuracy: 0.8219 - loss: 0.3594 - val_accuracy: 0.6994 - val_loss: 0.6215\n",
      "Epoch 4/5\n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m7:20\u001b[0m 3s/step - accuracy: 0.6960 - loss: 0.5853"
     ]
    }
   ],
   "source": [
    "# Імпорт необхідних бібліотек\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Завантаження даних IMDB\n",
    "max_features = 10000  # Кількість унікальних слів у датасеті\n",
    "maxlen = 500  # Максимальна довжина рецензії (кількість слів)\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Заповнення або обрізка рецензій до однакової довжини\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=maxlen)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=maxlen)\n",
    "\n",
    "# Функція для створення та тренування моделі\n",
    "def train_model(model, train_x, train_y, test_x, test_y, epochs=5, batch_size=64):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_x, train_y,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.2,\n",
    "                        verbose=1)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(test_x, test_y, verbose=2)\n",
    "    print(f'Accuracy on test set: {test_acc}')\n",
    "    return history\n",
    "\n",
    "# Простий RNN\n",
    "simple_rnn_model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128),\n",
    "    layers.SimpleRNN(128),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"Training Simple RNN model...\")\n",
    "simple_rnn_history = train_model(simple_rnn_model, train_x, train_y, test_x, test_y)\n",
    "\n",
    "# LSTM\n",
    "lstm_model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_history = train_model(lstm_model, train_x, train_y, test_x, test_y)\n",
    "\n",
    "# Двостороння LSTM\n",
    "bi_lstm_model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128),\n",
    "    layers.Bidirectional(layers.LSTM(128)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"Training Bidirectional LSTM model...\")\n",
    "bi_lstm_history = train_model(bi_lstm_model, train_x, train_y, test_x, test_y)\n",
    "\n",
    "# Глибока мережа з кількома LSTM шарами\n",
    "deep_lstm_model = models.Sequential([\n",
    "    layers.Embedding(input_dim=max_features, output_dim=128),\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.LSTM(128),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(\"Training Deep LSTM model...\")\n",
    "deep_lstm_history = train_model(deep_lstm_model, train_x, train_y, test_x, test_y)\n",
    "\n",
    "# Візуалізація результатів навчання\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(histories, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for name, history in histories:\n",
    "        val_acc = history.history['val_accuracy']\n",
    "        plt.plot(val_acc, label=name)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history([('Simple RNN', simple_rnn_history), \n",
    "              ('LSTM', lstm_history), \n",
    "              ('Bidirectional LSTM', bi_lstm_history), \n",
    "              ('Deep LSTM', deep_lstm_history)], \n",
    "             'Validation Accuracy of Different RNN Models')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пояснення коду:\n",
    "- Імпорт бібліотек:\n",
    "    - Імпортуємо необхідні модулі з TensorFlow, Keras та matplotlib.\n",
    "- Завантаження та підготовка даних:\n",
    "    - Завантажуємо датасет IMDB і обмежуємо кількість унікальних слів до 10,000. \n",
    "    - Також заповнюємо або обрізаємо рецензії до однакової довжини (500 слів).\n",
    "- Функція для тренування моделі:\n",
    "    - Створюємо функцію для компіляції, тренування та оцінки моделі.\n",
    "- Створення та тренування моделей:\n",
    "    - Простий RNN: Використовуємо шар SimpleRNN.\n",
    "- LSTM:\n",
    "    - Використовуємо шар LSTM.\n",
    "- Двостороння LSTM:\n",
    "    - Використовуємо шар Bidirectional з LSTM.\n",
    "- Глибока LSTM: Використовуємо кілька LSTM шарів.\n",
    "- Візуалізація результатів:\n",
    "    - Відображаємо графіки точності валідації для всіх моделей, щоб порівняти їх продуктивність.\n",
    "\n",
    "### Висновки:\n",
    "Після тренування моделей та візуалізації результатів можна порівняти точність різних архітектур. Ви побачите, яка модель показує кращі результати і робить найменше помилок. Наприклад, двосторонні та глибокі LSTM моделі часто показують кращу точність у порівнянні з простими RNN завдяки своїй здатності краще захоплювати контекст у послідовностях.\n",
    "\n",
    "Експериментуйте з різними архітектурами, кількістю нейронів, функціями активації, кількістю епох, розміром батчу та іншими гіперпараметрами, щоб знайти найкращу модель для вашого завдання."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasience-ZD1DWEDm-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
